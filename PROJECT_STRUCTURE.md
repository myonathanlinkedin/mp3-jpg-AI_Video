# Project Structure - AI Video Generator with Faiss Semantic Search

This document outlines the complete project architecture for the AI-powered lyric synchronization video generation system using Faiss semantic search.

## üìÅ Directory Structure

```
generatevideofromaudioimage/
‚îú‚îÄ‚îÄ ai_lyric_sync_generator.py    # Main application script
‚îú‚îÄ‚îÄ context/                      # Input/output directory
‚îÇ   ‚îú‚îÄ‚îÄ rapper.jpg               # Input image file
‚îÇ   ‚îú‚îÄ‚îÄ Title _ Judul_Black Chains _ Rantai Hi_cmp.mp3  # Input audio file
‚îÇ   ‚îî‚îÄ‚îÄ ai_lyric_sync_video.mp4  # Generated output video
‚îú‚îÄ‚îÄ README.md                     # Project overview and quick start
‚îú‚îÄ‚îÄ INSTALLATION.md               # Detailed installation instructions
‚îú‚îÄ‚îÄ USAGE.md                      # Comprehensive usage guide
‚îî‚îÄ‚îÄ PROJECT_STRUCTURE.md          # This file
```

## üéØ Core Components

### Main Application (`ai_lyric_sync_generator.py`)

The primary script that orchestrates the entire video generation process:

#### Class: `AILyricSyncGenerator`

**Key Methods:**
- `__init__()`: Initialize the generator with file paths
- `_get_audio_duration()`: Extract audio duration using librosa
- `_extract_text_from_audio()`: AI text extraction using Whisper
- `_match_extracted_text_with_lyrics()`: Intelligent text matching
- `_ensure_sequential_timing()`: Ensure all lyrics are displayed
- `_fallback_timing()`: Fallback timing for unmatched lyrics
- `_create_smooth_frames()`: Generate animated video frames
- `generate_video()`: Main orchestration method

**Dependencies:**
- `whisper`: AI text extraction
- `moviepy`: Video creation and editing
- `PIL/Pillow`: Image processing
- `librosa`: Audio analysis
- `numpy`: Numerical operations
- `faiss`: Semantic search engine
- `sentence_transformers`: Text embeddings
- `torch`: PyTorch framework

## üîß Technical Architecture

### AI Text Extraction Pipeline

1. **Whisper Model Loading**
   - Loads "base" model for balanced speed/accuracy
   - Supports CUDA acceleration when available
   - Caches model for multiple uses

2. **Audio Processing**
   - Transcribes audio with word-level timestamps
   - Extracts spoken text with precise timing
   - Handles multiple languages (detected automatically)

3. **Faiss Semantic Search**
   - Builds Faiss index with Sentence Transformers embeddings
   - Creates text chunks from extracted words
   - Performs semantic search for each lyric
   - Maps timing from AI extraction to provided lyrics
   - Ensures sequential timing for complete coverage

### Video Generation Pipeline

1. **Image Processing**
   - Resizes input image to 1024x1024 resolution
   - Applies multi-frequency transformations
   - Creates smooth zoom, pan, and rotation effects

2. **Frame Generation**
   - Generates 30 FPS video frames
   - Applies complex mathematical transformations
   - Adds synchronized lyric text with fade effects

3. **Video Composition**
   - Combines frames with original audio
   - Uses H.264 codec for optimal compression
   - Maintains high quality output

## üéµ Lyric Synchronization System

### Text Matching Strategy

1. **Full Text Search**
   - Searches entire extracted text for each lyric
   - Uses minimum 20% match ratio for flexibility
   - Prioritizes longest matches for accuracy

2. **Sequential Timing**
   - Ensures all lyrics are displayed from start to finish
   - Calculates average time per lyric
   - Provides fallback timing for unmatched lyrics

3. **Timing Validation**
   - Validates all timing data
   - Ensures no negative or invalid timestamps
   - Maintains chronological order

### Animation System

1. **Multi-Frequency Transformations**
   - Zoom: `1.0 + 0.05 * sin(2œÄ * progress)`
   - Pan X: `0.02 * sin(2œÄ * progress * 4)`
   - Pan Y: `0.02 * cos(2œÄ * progress * 3)`
   - Rotation: `1.0 * sin(2œÄ * progress * 2)`

2. **Text Effects**
   - Fade in/out with 0.5s duration
   - Black stroke outline for readability
   - Centered positioning at bottom of frame (120px from bottom)

## üìä Performance Characteristics

### Hardware Requirements

- **GPU**: CUDA-compatible (RTX 4090 recommended)
- **RAM**: 8GB+ recommended
- **Storage**: 2GB+ free space for models and output

### Processing Times

- **Text Extraction**: ~30-60 seconds for 4-minute audio
- **Frame Generation**: ~2-3 minutes for 4-minute video
- **Video Encoding**: ~1-2 minutes for final output

### Memory Usage

- **Whisper Model**: ~150MB RAM
- **Frame Generation**: ~500MB RAM peak
- **Video Encoding**: ~200MB RAM

## üîß Configuration Options

### Whisper Model Selection

```python
# Available models with trade-offs
"tiny"    # 39MB,  ~32x realtime, lowest accuracy
"base"    # 74MB,  ~16x realtime, balanced (recommended)
"small"   # 244MB, ~6x realtime, good accuracy
"medium"  # 769MB, ~2x realtime, high accuracy
"large"   # 1550MB, ~1x realtime, highest accuracy
```

### Video Quality Settings

```python
# Adjustable parameters
fps = 30                    # Frames per second
image_size = (1024, 1024)   # Output resolution
font_size = 40             # Text size
fade_duration = 0.3        # Text fade effect duration
```

### Text Matching Parameters

```python
# Matching sensitivity
similarity_threshold = 0.3  # Minimum semantic similarity threshold
lyric_coverage = 0.90       # Percentage of audio duration for lyrics
chunk_size = 5             # Words per text chunk for semantic search
```

## üöÄ Deployment Considerations

### Production Setup

1. **Model Caching**
   - Whisper models are cached locally after first download
   - Reduces startup time for subsequent runs

2. **Error Handling**
   - Graceful fallback for missing files
   - Comprehensive error logging
   - Progress tracking for long operations

3. **Resource Management**
   - Efficient memory usage
   - GPU memory optimization
   - Cleanup of temporary files

### Scalability Options

1. **Batch Processing**
   - Can process multiple audio files
   - Parallel processing capabilities
   - Queue-based processing for large volumes

2. **Cloud Deployment**
   - Docker containerization support
   - Kubernetes deployment ready
   - Auto-scaling capabilities

## üìà Future Enhancements

### Planned Features

1. **Advanced Text Matching**
   - Machine learning-based text alignment
   - Multi-language support improvements
   - Context-aware matching

2. **Animation Enhancements**
   - More complex transformation algorithms
   - Music-responsive animations
   - Custom animation presets

3. **Performance Optimizations**
   - GPU-accelerated frame generation
   - Parallel processing improvements
   - Memory usage optimization

### Integration Possibilities

1. **API Development**
   - RESTful API for web integration
   - Real-time processing capabilities
   - Batch processing endpoints

2. **Cloud Services**
   - AWS/Azure deployment options
   - Serverless function support
   - CDN integration for output delivery

This architecture provides a solid foundation for AI-powered lyric synchronization while maintaining flexibility for future enhancements and scalability requirements.